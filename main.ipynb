{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NASA: Asteroids Classification\n",
    "\n",
    "### Overview\n",
    "\n",
    "We were provided the NASA asteroids classification [dataset](https://www.kaggle.com/datasets/lovishbansal123/nasa-asteroids-classification). The dataset contains information about near-Earth asteroids, including features such as diameter, orbital period, semi-major axis, and whether they are hazardous.\n",
    "\n",
    "### Project Objectives\n",
    "\n",
    "1. **Identify Hazardous Asteroids**: Use the AI system to classify asteroids.\n",
    "2. **Feature Analysis**: Identify key features for classification.\n",
    "3. **Model Comparison**: Compare different machine learning algorithms.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all nessesary libraries\n",
    "import datetime\n",
    "import warnings\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sb\n",
    "from joblib import dump, load\n",
    "from tqdm import tqdm\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import StratifiedKFold, GridSearchCV, cross_val_predict, cross_validate, train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Set warnings \n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data processing\n",
    "\n",
    "### Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'data/nasa.csv'\n",
    "data = pd.read_csv(path)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()\n",
    "data['Hazardous'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Missing Values\n",
    "\n",
    "Check for Missing Values (NA) in a DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Is any data NA: {data.isna().any().any()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing Correlation Matrix Using Heatmap\n",
    "\n",
    "The purpose of this code snippet is to create a heatmap using seaborn to visualize the correlation matrix of relationships between different numerical columns in the dataset. Using that we can drop the unnecessary columns to optimize our models or analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(32,32))\n",
    "# sb.heatmap(data.corr(numeric_only=True), annot=True, fmt='.2f')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyzing High Correlations in Columns\n",
    "\n",
    "Based on the results, several columns have high correlations:\n",
    "\n",
    "1. **Name** and **Neo Reference ID**: These are just identifiers and do not contain useful information for analysis.\n",
    "\n",
    "2. **Est Dia in M(min)**, **Est Dia in Miles(min)** ... : All these values represent the same measurements but in different units. We can drop all but one.\n",
    "\n",
    "3. **Relative Velocity km per hr** and **Miles per hour**: Similar to the previous case, these values represent the same information but in different units.\n",
    "\n",
    "4. **Miss Dist.(Astronomical)** and **Miss Dist.(lunar)**: These also represent the same information but in different units.\n",
    "\n",
    "5. **Orbital Period**: This has a perfect correlation (1.0) with **Semi Major Axis**, due to the formula $T^2 = \\text{const} \\cdot a^3$, where $T$ is the Orbital Period and $a$ is the Semi Major Axis. We can drop one of them.\n",
    "\n",
    "6. **Est Dia in KM(max)**, **Jupiter Tisserand Invariant**, **Epoch Osculation**, **Aphelion Dist**: These columns have high correlations with other values.\n",
    "\n",
    "Additionally, we can drop the columns **Equinox** and **Orbiting Body**, as they contain only a single unique value: *J2000* and *Earth*, respectively.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Unique Equinox values: {data['Equinox'].nunique()}\")\n",
    "print(f\"Unique Orbiting Body values: {data['Orbiting Body'].nunique()}\")\n",
    "\n",
    "data = data.drop(['Name', 'Neo Reference ID', 'Orbit ID',   # IDs\n",
    "                    'Orbit Determination Date', 'Close Approach Date', # Date\n",
    "                    'Est Dia in M(min)', 'Est Dia in M(max)', 'Est Dia in Miles(min)', 'Est Dia in Miles(max)', 'Est Dia in Feet(min)', 'Est Dia in Feet(max)', # Distance\n",
    "                    'Relative Velocity km per hr', 'Miles per hour', # Velocity\n",
    "                    'Miss Dist.(Astronomical)', 'Miss Dist.(lunar)', 'Miss Dist.(miles)', # # Distance\n",
    "                    'Equinox',            # all 'J2000' \n",
    "                    'Orbiting Body',      # all 'Earth'\n",
    "                    'Orbital Period',     # T² = const * a³, => corr = 1 with Semi Major Axis (a)\n",
    "                    'Est Dia in KM(max)', # High correlation with Est Dia in KM(min)\n",
    "                    'Jupiter Tisserand Invariant', # High correlation with Mean Motion\n",
    "                    'Epoch Osculation',   # High correlation with Perihelion Time\n",
    "                    'Aphelion Dist',      # High correlation with Semi Major Axis\n",
    "                    ] , axis = 1)\n",
    "\n",
    "data['Hazardous'] = data['Hazardous'].astype(int)\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "New Correlation Matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(20,20))\n",
    "# sb.heatmap(data.corr(numeric_only=True), annot=True, fmt='.2f')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dropping outliers\n",
    "\n",
    "The goal of this section is to identify and potentially remove outliers from the dataset. \n",
    "\n",
    "Plotting Pairwise Relationships:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure()\n",
    "# sb.pairplot(data.dropna(), hue='Hazardous')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filter out outliers based on specific conditions, based on the estimated diameter (min) in kilometers, semi-major axis, and inclination, keeping only reasonable values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out outliers based on specific conditions\n",
    "df_no_outliers = data[(data['Est Dia in KM(min)'] <= 10) & \n",
    "                    (data['Semi Major Axis'] <= 4) &\n",
    "                    (data['Inclination'] < 70)]\n",
    "\n",
    "# Reset the index of the filtered DataFrame\n",
    "df_no_outliers.reset_index(inplace=True, drop=True)\n",
    "\n",
    "print(f\"Number of objects before: {data.shape[0]}, after: {df_no_outliers.shape[0]}, dropped: {data.shape[0] - df_no_outliers.shape[0]} objects.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure()\n",
    "# sb.pairplot(df_no_outliers.dropna(), hue='Hazardous')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save clean data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_data_path = 'data/nasa_clean.csv'\n",
    "print(f\"Saving data to {clean_data_path} ...\")\n",
    "df_no_outliers.to_csv(clean_data_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models training\n",
    "\n",
    "### Preparation\n",
    "\n",
    "Separate the features (X) and the target variable (y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_no_outliers.drop(['Hazardous'], axis=1)\n",
    "y = df_no_outliers['Hazardous']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scale the numerical features of the dataset to have zero mean and unit variance. This standardization helps to improve the performance of many machine learning algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_transformer = StandardScaler()\n",
    "\n",
    "preprocessor = ColumnTransformer([\n",
    "    (\"num\", numerical_transformer, X.columns.to_list()),\n",
    "])\n",
    "\n",
    "preprocessor.fit(X_train)\n",
    "\n",
    "x_train_transformed = preprocessor.transform(X_train)\n",
    "x_test_transformed = preprocessor.transform(X_test)\n",
    "\n",
    "print(\"Transformed data:\")\n",
    "pd.DataFrame(x_train_transformed, columns=X.columns).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_metric_resuts(df_results, names):\n",
    "    scores = ['Acc Test', 'Pre Test', 'Rec Test', 'F1 Test']\n",
    "    heatmap_data = df_results[scores].transpose()\n",
    "\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    ax = sb.heatmap(heatmap_data, annot=True, cmap='Blues', cbar=True, xticklabels=names, yticklabels=scores)\n",
    "    ax.set_title(\"Model Performance Heatmap (Test Set)\")\n",
    "    ax.set_xlabel(\"Models\")\n",
    "    ax.set_ylabel(\"Metrics\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def plot_boxplots(results_acc, results_pre, results_rec, results_f1, names):\n",
    "    # Create boxplots\n",
    "    fig, axes = plt.subplots(nrows=1, ncols=4, figsize=(18, 6))\n",
    "\n",
    "    plot_titles = ['Accuracy', 'Precision', 'Recall', 'F1-Score']\n",
    "    results_list = [results_acc, results_pre, results_rec, results_f1]\n",
    "\n",
    "    palette = sb.color_palette(\"Blues\")\n",
    "    for ax, title, result in zip(axes, plot_titles, results_list):\n",
    "        sb.boxplot(data=result, ax=ax, palette=palette)\n",
    "        ax.set_title(title, fontsize=14)\n",
    "        ax.set_xticklabels(names, rotation=30)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def plot_confusion_matrices(models, confusion_matrices, names):\n",
    "    # Create Confusion Matrices\n",
    "    fig, axes = plt.subplots(1, len(models), figsize=(5 * len(models), 4))\n",
    "    if len(models) == 1:\n",
    "        axes = [axes]\n",
    "    for ax, cm, name in zip(axes, confusion_matrices, names):\n",
    "        sb.heatmap(cm / np.sum(cm), annot=True, fmt=\".2%\", ax=ax, cmap='Blues')\n",
    "        ax.set_title(f'{name} Confusion Matrix')\n",
    "        ax.set_xlabel('Predicted labels')\n",
    "        ax.set_ylabel('True labels')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_evaluation(x_train, y_train, x_test, y_test, models):\n",
    "    names = []\n",
    "    scoring = ['accuracy', 'precision', 'recall', 'f1']\n",
    "    \n",
    "    # Create a dataframe to store the different metric values for each algorithm\n",
    "    df_results = pd.DataFrame(columns=['Algorithm', 'Acc Train Mean', 'Acc Train STD', 'Pre Train Mean', 'Pre Train STD', \n",
    "                                       'Rec Train Mean', 'Rec Train STD', 'F1 Train Mean', 'F1 Train STD',\n",
    "                                       'Acc Test', 'Pre Test', 'Rec Test', 'F1 Test', 'Training Time'])\n",
    "    results_acc_test = []\n",
    "    results_pre_test = []\n",
    "    results_rec_test = []\n",
    "    results_f1_test = []\n",
    "    results_acc = []\n",
    "    results_pre = []\n",
    "    results_rec = []\n",
    "    results_f1 = [] \n",
    "    confusion_matrices = []\n",
    "    \n",
    "    kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "    for name, model in tqdm(models, total=len(models)):\n",
    "        names.append(name)\n",
    "\n",
    "        # Cross-validation results on the training set\n",
    "        result = cross_validate(model, x_train, y_train, cv=kfold, scoring=scoring, return_train_score=False)\n",
    "        model.fit(x_train, y_train)\n",
    "        \n",
    "        # Test set results\n",
    "        predictions = model.predict(x_test)\n",
    "        cm = confusion_matrix(y_test, predictions)\n",
    "        confusion_matrices.append(cm)\n",
    "        accuracy_test = accuracy_score(y_test, predictions)\n",
    "        precision_test = precision_score(y_test, predictions, zero_division=1)\n",
    "        recall_test = recall_score(y_test, predictions)\n",
    "        f1_test = f1_score(y_test, predictions)\n",
    "        \n",
    "        # Store the test set results (single values)\n",
    "        results_acc_test.append(accuracy_test)\n",
    "        results_pre_test.append(precision_test)\n",
    "        results_rec_test.append(recall_test)\n",
    "        results_f1_test.append(f1_test)\n",
    "        results_acc.append(result['test_accuracy'])\n",
    "        results_pre.append(result['test_precision'])\n",
    "        results_rec.append(result['test_recall'])\n",
    "        results_f1.append(result['test_f1'])\n",
    "\n",
    "        # Row of results\n",
    "        model_results = pd.DataFrame({'Algorithm': name, \n",
    "                                      'Acc Test': accuracy_test,\n",
    "                                      'Pre Test': precision_test,\n",
    "                                      'Rec Test': recall_test,\n",
    "                                      'F1 Test': f1_test,\n",
    "                                      'Acc Train Mean': result['test_accuracy'].mean(), \n",
    "                                      'Acc Train STD': result['test_accuracy'].std(), \n",
    "                                      'Pre Train Mean': result['test_precision'].mean(), \n",
    "                                      'Pre Train STD': result['test_precision'].std(), \n",
    "                                      'Rec Train Mean': result['test_recall'].mean(), \n",
    "                                      'Rec Train STD': result['test_recall'].std(), \n",
    "                                      'F1 Train Mean': result['test_f1'].mean(), \n",
    "                                      'F1 Train STD': result['test_f1'].std(),\n",
    "                                      'Training Time': result['fit_time'].mean(),\n",
    "                                      }, index=[0])\n",
    "        \n",
    "        # Add the row to the results data frame\n",
    "        if not model_results.empty:\n",
    "            df_results = pd.concat([df_results, model_results], ignore_index=True)\n",
    "        \n",
    "        # Save model.\n",
    "        current_time = datetime.datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "        # dump(model, f'models/{name}_{current_time}_classifier.joblib')\n",
    "\n",
    "\n",
    "    df_results = df_results.set_index('Algorithm')\n",
    "    pd.set_option('display.float_format', lambda x: '%.3f' % x)\n",
    "    pd.set_option('display.width', 1000)\n",
    "    print(df_results)\n",
    "\n",
    "\n",
    "    # Show different plots\n",
    "    plot_metric_resuts(df_results, names)\n",
    "    plot_boxplots(results_acc, results_pre, results_rec, results_f1, names)\n",
    "    plot_confusion_matrices(models, confusion_matrices, names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = []\n",
    "models.append(('SVC', SVC()))\n",
    "models.append(('DTC', DecisionTreeClassifier()))\n",
    "models.append(('KNN', KNeighborsClassifier()))\n",
    "models.append(('GNB', GaussianNB()))\n",
    "models.append(('XGB', XGBClassifier()))\n",
    "models.append(('MLP', MLPClassifier()))\n",
    "\n",
    "model_evaluation(x_train_transformed, y_train, x_test_transformed, y_test, models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = []\n",
    "models.append(('RFC', RandomForestClassifier()))\n",
    "models.append(('ABC', AdaBoostClassifier(algorithm='SAMME')))\n",
    "models.append(('GBC', GradientBoostingClassifier()))\n",
    "models.append(('LR', LogisticRegression(max_iter=1000)))\n",
    "models.append(('LGBM', LGBMClassifier(verbose=-1)))\n",
    "\n",
    "\n",
    "model_evaluation(x_train_transformed, y_train, x_test_transformed, y_test, models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid search\n",
    "\n",
    "In this section, we'll use the Grid Search algorithm to improve the performance of two models: the best and worst models from our previous evaluations.\n",
    "\n",
    "* Best model: [RandomForestClassifire](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html)\n",
    "* Worst model: [KNeighborsClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier()\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],  \n",
    "    'max_features': ['auto', 'sqrt', 'log2'], \n",
    "    'max_depth': [None, 5, 10, 20, 30],  \n",
    "    'min_samples_split' : [1, 2, 3],\n",
    "    'criterion': ['gini', 'entropy']  \n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(estimator=rf, param_grid=param_grid, cv=5, verbose=1, n_jobs=-1)\n",
    "\n",
    "grid_search.fit(x_train_transformed, y_train)\n",
    "\n",
    "best_rf = grid_search.best_estimator_\n",
    "\n",
    "predictions = best_rf.predict(x_test_transformed)\n",
    "\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "\n",
    "print(\"Best parameters found: \", grid_search.best_params_)\n",
    "print(\"Test accuracy of the best model: \", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier()\n",
    "\n",
    "param_grid = {\n",
    "    'n_neighbors': [3, 5, 7, 10, 15],  \n",
    "    'weights': ['uniform', 'distance'],  \n",
    "    'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute'], \n",
    "    'leaf_size': [15, 20, 30, 40], \n",
    "    'p': [1, 1.25, 1.5, 1.75, 2]  \n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(estimator=knn, param_grid=param_grid, cv=5, verbose=1, n_jobs=-1)\n",
    "\n",
    "grid_search.fit(x_train_transformed, y_train)\n",
    "\n",
    "best_knn = grid_search.best_estimator_\n",
    "\n",
    "predictions = best_knn.predict(x_test_transformed)\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "\n",
    "print(\"Best parameters found: \", grid_search.best_params_)\n",
    "print(\"Test accuracy of the best model: \", accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
